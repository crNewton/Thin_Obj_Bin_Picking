{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import copy\n",
    "import re\n",
    "\n",
    "# import from ROS\n",
    "import rospy\n",
    "import roslib\n",
    "import actionlib\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import moveit_commander\n",
    "import tf\n",
    "\n",
    "# messages\n",
    "import geometry_msgs.msg\n",
    "from sensor_msgs.msg import JointState, Image\n",
    "from std_msgs.msg import String\n",
    "from thin_obj_bin_picking.msg import img_status\n",
    "import moveit_msgs.msg\n",
    "from trajectory_msgs.msg import JointTrajectoryPoint\n",
    "from robotiq_force_torque_sensor.msg import ft_sensor\n",
    "from robotiq_c_model_control.msg import _CModel_robot_output as outputMsg\n",
    "from thin_obj_bin_picking.msg import blister_pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Starting tutorial setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ros/kinetic/lib/python2.7/dist-packages/moveit_commander/planning_scene_interface.py:49: SyntaxWarning: The publisher should be created with an explicit keyword argument 'queue_size'. Please see http://wiki.ros.org/rospy/Overview/Publishers%20and%20Subscribers for more information.\n",
      "  self._pub_co = rospy.Publisher('/collision_object', CollisionObject)\n",
      "/opt/ros/kinetic/lib/python2.7/dist-packages/moveit_commander/planning_scene_interface.py:50: SyntaxWarning: The publisher should be created with an explicit keyword argument 'queue_size'. Please see http://wiki.ros.org/rospy/Overview/Publishers%20and%20Subscribers for more information.\n",
      "  self._pub_aco = rospy.Publisher('/attached_collision_object', AttachedCollisionObject)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Waiting for RVIZ...\n",
      "============ Starting tutorial \n",
      "============ Reference frame: /world\n",
      "============ Reference frame: ee_link\n",
      "============ Robot Groups:\n",
      "['endeffector', 'manipulator']\n",
      "============ Printing robot state\n",
      "joint_state: \n",
      "  header: \n",
      "    seq: 0\n",
      "    stamp: \n",
      "      secs: 0\n",
      "      nsecs:         0\n",
      "    frame_id: \"/world\"\n",
      "  name: [shoulder_pan_joint, shoulder_lift_joint, elbow_joint, wrist_1_joint, wrist_2_joint,\n",
      "  wrist_3_joint]\n",
      "  position: [-0.00034743944276982575, -1.1873648802386683, -2.4050851503955286, -1.1196516195880335, 1.5709065198898315, -1.571204964314596]\n",
      "  velocity: []\n",
      "  effort: []\n",
      "multi_dof_joint_state: \n",
      "  header: \n",
      "    seq: 0\n",
      "    stamp: \n",
      "      secs: 0\n",
      "      nsecs:         0\n",
      "    frame_id: \"/world\"\n",
      "  joint_names: []\n",
      "  transforms: []\n",
      "  twist: []\n",
      "  wrench: []\n",
      "attached_collision_objects: []\n",
      "is_diff: False\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "listener = tf.TransformListener()\n",
    "\n",
    "## First initialize moveit_commander and rospy.\n",
    "moveit_commander.roscpp_initialize(sys.argv)\n",
    "rospy.init_node('blister_bin_pick',\n",
    "                  anonymous=True)\n",
    "robot = moveit_commander.RobotCommander()\n",
    "scene = moveit_commander.PlanningSceneInterface()\n",
    "group = moveit_commander.MoveGroupCommander(\"manipulator\") \n",
    "display_trajectory_publisher = rospy.Publisher(\n",
    "                                    '/move_group/display_planned_path',\n",
    "                                    moveit_msgs.msg.DisplayTrajectory,\n",
    "                                    queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust action speed by trajectory interpolation\n",
    "def scale_trajectory_speed(traj, scale):\n",
    "        new_traj = RobotTrajectory()\n",
    "        new_traj.joint_trajectory = traj.joint_trajectory\n",
    "        n_joints = len(traj.joint_trajectory.joint_names)\n",
    "        n_points = len(traj.joint_trajectory.points)\n",
    "        points = list(traj.joint_trajectory.points)\n",
    "        for i in range(n_points):\n",
    "            point = JointTrajectoryPoint()\n",
    "            point.time_from_start = traj.joint_trajectory.points[i].time_from_start / scale\n",
    "            point.velocities = list(traj.joint_trajectory.points[i].velocities)\n",
    "            point.accelerations = list(traj.joint_trajectory.points[i].accelerations)\n",
    "            point.positions = traj.joint_trajectory.points[i].positions                        \n",
    "            for j in range(n_joints):\n",
    "                point.velocities[j] = point.velocities[j] * scale\n",
    "                point.accelerations[j] = point.accelerations[j] * scale * scale           \n",
    "            points[i] = point\n",
    "        new_traj.joint_trajectory.points = points\n",
    "        return new_traj\n",
    "\n",
    "# Gripper position and velocity control for Robotiq C_Model gripper\n",
    "def gripper_position(degree):\n",
    "    command = outputMsg.CModel_robot_output();\n",
    "    command.rACT = 1\n",
    "    command.rGTO = 1\n",
    "    command.rPR = degree\n",
    "    command.rSP  = 0\n",
    "    command.rFR  = 150\n",
    "    gripper_set_vel_pub.publish(command)\n",
    "\n",
    "# Define home pose\n",
    "def go_to_home(wait):\n",
    "    group.clear_pose_targets()\n",
    "    group_variable_values = group.get_current_joint_values()\n",
    "    group_variable_values[0] = 0\n",
    "    group_variable_values[1] = -pi*68.03/180\n",
    "    group_variable_values[2] = -pi*137.81/180\n",
    "    group_variable_values[3] = -pi*3/2-(group_variable_values[1]+group_variable_values[2])\n",
    "    group_variable_values[4] = pi*1/2\n",
    "    group_variable_values[5] = -pi/2\n",
    "    group.set_joint_value_target(group_variable_values)\n",
    "    plan = group.plan()\n",
    "    rospy.sleep(2)\n",
    "    scaled_traj2 = scale_trajectory_speed(plan, 0.2)\n",
    "    group.execute(scaled_traj2, wait)\n",
    "\n",
    "# Define destination pose    \n",
    "def go_to_box(wait):\n",
    "    group.clear_pose_targets()\n",
    "    group_variable_values = group.get_current_joint_values()\n",
    "    group_variable_values[0] = 21.55*pi/180 \n",
    "    group_variable_values[1] = -pi*64.05/180\n",
    "    group_variable_values[2] = -pi*140/180 \n",
    "    group_variable_values[3] = -pi*3/2-(group_variable_values[1]+group_variable_values[2])\n",
    "    group_variable_values[4] = pi*1/2\n",
    "    group_variable_values[5] = -pi*69/180\n",
    "    group.set_joint_value_target(group_variable_values)\n",
    "    plan = group.plan()move_waypoints\n",
    "    rospy.sleep(2)\n",
    "    scaled_traj2 = scale_trajectory_speed(plan, 0.2)\n",
    "    group.execute(scaled_traj2, wait)\n",
    "\n",
    "def move_waypoints(px, py, pz, vel, wait):\n",
    "    waypoints = []\n",
    "    waypoints.append(group.get_current_pose().pose)\n",
    "    wpose = copy.deepcopy(group.get_current_pose().pose)\n",
    "    wpose.position.x = px\n",
    "    wpose.position.y = py\n",
    "    wpose.position.z = pz\n",
    "    waypoints.append(copy.deepcopy(wpose))\n",
    "    (plan, fraction) = group.compute_cartesian_path(waypoints, 0.01, 0.0)\n",
    "    scaled_traj = scale_trajectory_speed(plan, vel)\n",
    "    group.execute(scaled_traj, wait)       \n",
    "\n",
    "def move_target(x, y, z, ox, oy, oz, ow, vel, wait):\n",
    "    pose_target = geometry_msgs.msg.Pose()\n",
    "    pose_target.orientation.x = ox\n",
    "    pose_target.orientation.y = oy\n",
    "    pose_target.orientation.z = oz\n",
    "    pose_target.orientation.w = ow\n",
    "    pose_target.position.x = x\n",
    "    pose_target.position.y = y\n",
    "    pose_target.position.z = z\n",
    "    group.set_pose_target(pose_target)\n",
    "    plan = group.plan()\n",
    "    scaled_traj = scale_trajectory_speed(plan, vel)\n",
    "    group.execute(scaled_traj, wait)\n",
    "\n",
    "# Translate and rotate the manipulator along a frame\n",
    "def move_tip(x, y, z, rx, ry, rz, vel, tg_frame, wait):\n",
    "    (base_g_trans,base_g_rot) = listener.lookupTransform('/base_link', tg_frame, rospy.Time(0)) \n",
    "    base_g_rot_mat = tf.transformations.quaternion_matrix(base_g_rot)\n",
    "    zaxis = (0, 0, 1)\n",
    "    yaxis = (0, 1, 0)\n",
    "    xaxis = (1, 0, 0)\n",
    "    Rx = tf.transformations.rotation_matrix(rx, xaxis)\n",
    "    Ry = tf.transformations.rotation_matrix(ry, yaxis)\n",
    "    Rz = tf.transformations.rotation_matrix(rz, zaxis)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat, Rx)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat_new, Ry)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat_new, Rz)\n",
    "    move_frame_xyz = numpy.array([x, y, z, 1])\n",
    "    base_g_rot_mat[:3,3] = numpy.array(base_g_trans)\n",
    "    base_g_trans_new = numpy.dot(base_g_rot_mat, move_frame_xyz)\n",
    "    base_g_rot_mat_new[:3,3] = numpy.array([base_g_trans_new[0], base_g_trans_new[1], base_g_trans_new[2]])\n",
    "    (g_ee_trans,g_ee_rot) = listener.lookupTransform(tg_frame, '/ee_link', rospy.Time(0)) \n",
    "    g_ee_rot_mat = tf.transformations.quaternion_matrix(g_ee_rot)\n",
    "    g_ee_rot_mat[:3,3] = numpy.array(g_ee_trans)\n",
    "    base_ee_homo_new = numpy.dot(base_g_rot_mat_new, g_ee_rot_mat)\n",
    "    desire_ee_trans = base_ee_homo_new[:3,3]\n",
    "    desire_ee_euler = tf.transformations.euler_from_matrix(base_ee_homo_new, axes='sxyz')\n",
    "    desire_ee_q = tf.transformations.quaternion_from_euler(desire_ee_euler[0], desire_ee_euler[1], desire_ee_euler[2], axes='sxyz')\n",
    "    if rx != 0.0 or ry!= 0.0 or rz != 0.0:\n",
    "        move_target(desire_ee_trans[0], desire_ee_trans[1], desire_ee_trans[2], desire_ee_q[0], desire_ee_q[1], desire_ee_q[2], desire_ee_q[3], vel, wait)\n",
    "    else:\n",
    "        move_waypoints(desire_ee_trans[0], desire_ee_trans[1], desire_ee_trans[2], vel, wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_send_img = 0\n",
    "img_count = 0\n",
    "pose_x = 0\n",
    "pose_y = 0\n",
    "angle = 0\n",
    "bridge = CvBridge()\n",
    "\n",
    "whether_left = True\n",
    "whether_finish = True\n",
    "whether_tilt = False\n",
    "left_sensor_bd = 0\n",
    "right_sensor_bd = 0\n",
    "\n",
    "# Thin objects bin picking manipulation\n",
    "def pose_callback(data):\n",
    "    global pose_x, pose_y, angle, whether_left, whether_finish, whether_tilt, left_sensor_bd, right_sensor_bd, is_send_img, pres_int_list_temp\n",
    "    pose_x = data.x\n",
    "    pose_y = data.y\n",
    "    angle = data.angle\n",
    "    left_sensor_bd = 0\n",
    "    right_sensor_bd = 0\n",
    "    whether_tilt = False\n",
    "    \n",
    "    # Detect\n",
    "    (c_ee_trans,c_ee_rot) = listener.lookupTransform('/ee_link', '/camera_link', rospy.Time(0))\n",
    "    c_ee_homo = tf.transformations.quaternion_matrix(c_ee_rot)\n",
    "    c_ee_homo[:3,3] = np.array([c_ee_trans[0], c_ee_trans[1], c_ee_trans[2]])\n",
    "    target_pos = np.dot(c_ee_homo, np.array([pose_x, pose_y, 0, 1]))\n",
    "    \n",
    "    # Approach\n",
    "    move_tip(0, pose_y-0.16375, -pose_x-0.014, 0, 0, 0, 0.2, 'ee_link', True)\n",
    "    rospy.sleep(0.5)\n",
    "    move_tip(0, 0, 0, pi/2+angle*pi/180, 0, 0, 0.2, 'ee_link', True)\n",
    "    rospy.sleep(0.5)\n",
    "    \n",
    "    # Descend\n",
    "    whether_finish = False\n",
    "    if whether_tilt == False and whether_finish == False:\n",
    "        move_tip(0.095, 0, 0, 0, 0, 0, 0.05, 'ee_link', False)  \n",
    "        left_sensor_bd = pres_int_list_temp[0]\n",
    "        right_sensor_bd = pres_int_list_temp[1]\n",
    "        while(whether_tilt == False):\n",
    "            pass\n",
    "        \n",
    "    # Tilt\n",
    "    if whether_tilt == True and whether_finish == False and whether_left==True:\n",
    "        move_tip(0,0,0,0,0,-10*pi/180, 0.05, 'left_fgtip', False) # 20 degree\n",
    "        temp_time=time.time()\n",
    "        temp_time1=temp_time\n",
    "        while(whether_tilt == True):\n",
    "            temp_time1=time.time()\n",
    "            if (temp_time1-temp_time)>4:\n",
    "                group.stop()\n",
    "                whether_tilt = False\n",
    "\n",
    "        gripper_position(173) \n",
    "        rospy.sleep(1)\n",
    "        go_to_box(True)\n",
    "        gripper_position(140) \n",
    "        rospy.sleep(0.5)\n",
    "        go_to_home(True)\n",
    "        rospy.sleep(4)\n",
    "        whether_finish = True\n",
    "        is_send_img = 1\n",
    "        \n",
    "    if whether_tilt == True and whether_finish == False and whether_left==False:\n",
    "        move_tip(0,0,0,0,0,10*pi/180, 0.05, 'right_fgtip', False)\n",
    "        temp_time=time.time()\n",
    "        temp_time1=temp_time\n",
    "        while(whether_tilt == True):\n",
    "            temp_time1=time.time()\n",
    "            if (temp_time1-temp_time)>4:\n",
    "                group.stop()\n",
    "                whether_tilt = False\n",
    "                \n",
    "        gripper_position(173)\n",
    "        rospy.sleep(1)\n",
    "        go_to_box(True)\n",
    "        gripper_position(140)\n",
    "        rospy.sleep(0.5)\n",
    "        go_to_home(True)\n",
    "        rospy.sleep(4)\n",
    "        whether_finish = True\n",
    "        is_send_img = 1\n",
    "\n",
    "# Subscribe image data from camera\n",
    "def image_callback(msg):\n",
    "    global img_count\n",
    "    global is_send_img\n",
    "    global pose_x, pose_y, angle\n",
    "    img_count_pub = rospy.Publisher('/img_index', String, queue_size=1)\n",
    "    if is_send_img == 1:\n",
    "        cv2_img = bridge.imgmsg_to_cv2(msg, \"bgr8\")\n",
    "        cv2.imwrite('../image/'+str(img_count)+'.jpeg', cv2_img)\n",
    "        img_count_pub.publish(str(img_count))\n",
    "        rospy.sleep(1)\n",
    "        img_count =img_count + 1\n",
    "        is_send_img = 0\n",
    "\n",
    "# Subscribe pressure data from tactile sensors\n",
    "def sensor_callback(data):\n",
    "    pressure_raw = data.data\n",
    "    global whether_left, whether_finish, whether_tilt, is_send_img, left_sensor_bd, right_sensor_bd, pres_int_list_temp\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    temp_pres_char_list = re.findall(pattern, pressure_raw)\n",
    "    pres_int_list = []\n",
    "    for i in temp_pres_char_list:\n",
    "        pres_int_list.append(int(i))\n",
    "    pres_int_list_temp = pres_int_list\n",
    "    \n",
    "    left_delta = left_sensor_bd - pres_int_list[0]\n",
    "    right_delta = right_sensor_bd - pres_int_list[1]\n",
    "    if whether_finish == False:\n",
    "        if whether_tilt == False:\n",
    "            if (left_delta > 10 or right_delta > 10) and whether_finish == False:\n",
    "                group.stop()\n",
    "                if left_delta > 10:\n",
    "                    whether_left = True\n",
    "                elif right_delta > 10:\n",
    "                    whether_left = False\n",
    "                whether_tilt = True\n",
    "        else:\n",
    "            if whether_left == True and whether_finish == False and right_delta > 10:\n",
    "                group.stop()\n",
    "                whether_tilt = False\n",
    "            elif whether_left == False and whether_finish == False and left_delta > 10:\n",
    "                group.stop()\n",
    "                whether_tilt = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7301706d7253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg_count_pub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPublisher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/img_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mString\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubscriber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubscriber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/blister_pose\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblister_pose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSubscriber\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/pressure\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mString\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_callback' is not defined"
     ]
    }
   ],
   "source": [
    "image_topic = '/camera/color/image_raw' \n",
    "img_count_pub = rospy.Publisher('/img_index', String, queue_size=10)\n",
    "\n",
    "rospy.Subscriber(image_topic, Image, image_callback)\n",
    "rospy.Subscriber(\"/blister_pose\", blister_pose, pose_callback)\n",
    "rospy.Subscriber(\"/pressure\", String, sensor_callback)\n",
    "\n",
    "go_to_home(False)\n",
    "global gripper_pub\n",
    "gripper_pub = rospy.Publisher('/robot_gripper_auto_control', String, queue_size=10)\n",
    "gripper_set_vel_pub = rospy.Publisher('CModelRobotOutput', outputMsg.CModel_robot_output, queue_size=10)\n",
    "rospy.sleep(0.5)\n",
    "gripper_pub.publish('a')\n",
    "rospy.sleep(0.5)\n",
    "gripper_position(140)\n",
    "rospy.sleep(4)\n",
    "is_send_img = 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
