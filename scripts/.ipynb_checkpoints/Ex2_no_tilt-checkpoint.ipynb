{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# ROS packages\n",
    "import numpy as np\n",
    "import rospy\n",
    "import geometry_msgs.msg\n",
    "import time\n",
    "import roslib; roslib.load_manifest('ur_driver')\n",
    "import actionlib\n",
    "# ROS Image message\n",
    "from sensor_msgs.msg import Image\n",
    "from std_msgs.msg import String\n",
    "from thin_obj_bin_picking.msg import img_status\n",
    "# ROS Image message -> OpenCV2 image converter\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "#import tf\n",
    "\n",
    "import numpy\n",
    "import sys\n",
    "import copy\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "import tf\n",
    "import math\n",
    "from sensor_msgs.msg import JointState\n",
    "from math import pi, sin, cos, atan2\n",
    "from moveit_msgs.msg import RobotTrajectory\n",
    "from trajectory_msgs.msg import JointTrajectoryPoint\n",
    "from geometry_msgs.msg import PoseStamped, Pose\n",
    "from math import sqrt, pi, acos, sin, cos\n",
    "from robotiq_force_torque_sensor.msg import ft_sensor\n",
    "from robotiq_c_model_control.msg import _CModel_robot_output as outputMsg\n",
    "from thin_obj_bin_picking.msg import blister_pose\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Starting tutorial setup\n",
      "============ Waiting for RVIZ...\n",
      "============ Starting tutorial \n",
      "============ Reference frame: /world\n",
      "============ Reference frame: ee_link\n",
      "============ Robot Groups:\n",
      "['endeffector', 'manipulator']\n",
      "============ Printing robot state\n",
      "joint_state: \n",
      "  header: \n",
      "    seq: 0\n",
      "    stamp: \n",
      "      secs: 0\n",
      "      nsecs:         0\n",
      "    frame_id: \"/world\"\n",
      "  name: [shoulder_pan_joint, shoulder_lift_joint, elbow_joint, wrist_1_joint, wrist_2_joint,\n",
      "  wrist_3_joint]\n",
      "  position: [-0.00014382997621709137, -1.4142869154559534, -2.2497528235064905, -1.0482247511493128, 1.5707746744155884, -1.5708578268634241]\n",
      "  velocity: []\n",
      "  effort: []\n",
      "multi_dof_joint_state: \n",
      "  header: \n",
      "    seq: 0\n",
      "    stamp: \n",
      "      secs: 0\n",
      "      nsecs:         0\n",
      "    frame_id: \"/world\"\n",
      "  joint_names: []\n",
      "  transforms: []\n",
      "  twist: []\n",
      "  wrench: []\n",
      "attached_collision_objects: []\n",
      "is_diff: False\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "listener = tf.TransformListener()\n",
    "\n",
    "## First initialize moveit_commander and rospy.\n",
    "print \"============ Starting tutorial setup\"\n",
    "moveit_commander.roscpp_initialize(sys.argv)\n",
    "rospy.init_node('blister_pick',\n",
    "                  anonymous=True)\n",
    "robot = moveit_commander.RobotCommander()\n",
    "scene = moveit_commander.PlanningSceneInterface()\n",
    "group = moveit_commander.MoveGroupCommander(\"manipulator\")\n",
    "\n",
    "print \"============ Waiting for RVIZ...\"\n",
    "print \"============ Starting tutorial \"\n",
    "\n",
    "print \"============ Reference frame: %s\" % group.get_planning_frame()\n",
    "\n",
    "print \"============ Reference frame: %s\" % group.get_end_effector_link()\n",
    "\n",
    "print \"============ Robot Groups:\"\n",
    "print robot.get_group_names()\n",
    "\n",
    "print \"============ Printing robot state\"\n",
    "print robot.get_current_state()\n",
    "print \"============\"\n",
    "  \n",
    "display_trajectory_publisher = rospy.Publisher(\n",
    "                                    '/move_group/display_planned_path',\n",
    "                                    moveit_msgs.msg.DisplayTrajectory,\n",
    "                                    queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_trajectory_speed(traj, scale):\n",
    "       # Create a new trajectory object\n",
    "        new_traj = RobotTrajectory()\n",
    "      \n",
    "       # Initialize the new trajectory to be the same as the planned trajectory\n",
    "        new_traj.joint_trajectory = traj.joint_trajectory\n",
    "      \n",
    "       # Get the number of joints involved\n",
    "        n_joints = len(traj.joint_trajectory.joint_names)\n",
    "      \n",
    "       # Get the number of points on the trajectory\n",
    "        n_points = len(traj.joint_trajectory.points)\n",
    "       \n",
    "       # Store the trajectory points\n",
    "        points = list(traj.joint_trajectory.points)\n",
    "      \n",
    "       # Cycle through all points and scale the time from start, speed and acceleration\n",
    "        for i in range(n_points):\n",
    "            point = JointTrajectoryPoint()\n",
    "            point.time_from_start = traj.joint_trajectory.points[i].time_from_start / scale\n",
    "            point.velocities = list(traj.joint_trajectory.points[i].velocities)\n",
    "            point.accelerations = list(traj.joint_trajectory.points[i].accelerations)\n",
    "            point.positions = traj.joint_trajectory.points[i].positions\n",
    "                        \n",
    "            for j in range(n_joints):\n",
    "                point.velocities[j] = point.velocities[j] * scale\n",
    "                point.accelerations[j] = point.accelerations[j] * scale * scale\n",
    "           \n",
    "            points[i] = point\n",
    "\n",
    "       # Assign the modified points to the new trajectory\n",
    "        new_traj.joint_trajectory.points = points\n",
    "        \n",
    "       # Return the new trajecotry\n",
    "        return new_traj\n",
    "\n",
    "def gripper_position(degree):\n",
    "    command = outputMsg.CModel_robot_output();\n",
    "    command.rACT = 1\n",
    "    command.rGTO = 1\n",
    "    command.rPR = degree\n",
    "    command.rSP  = 0\n",
    "    command.rFR  = 150 ##force need to be adjusted later\n",
    "    gripper_set_vel_pub.publish(command)\n",
    "    \n",
    "    \n",
    "def add_collision_object(xp, yp, zp, rx, ry, rz, rw, x_length, y_length, z_length, name):\n",
    "    ## Add collision object\n",
    "    obj_pose = geometry_msgs.msg.PoseStamped()\n",
    "    obj_pose.header.frame_id = robot.get_planning_frame()\n",
    "    obj_pose.pose.position.x = xp\n",
    "    obj_pose.pose.position.y = yp\n",
    "    obj_pose.pose.position.z = zp\n",
    "    obj_pose.pose.orientation.x = rx\n",
    "    obj_pose.pose.orientation.y = ry\n",
    "    obj_pose.pose.orientation.z = rz\n",
    "    obj_pose.pose.orientation.w = rw\n",
    "    scene.add_box(name, obj_pose, (x_length, y_length, z_length)) # x_axis, y_axis, z_axis\n",
    "    #print \"add collision\", obj_pose\n",
    "\n",
    "def quat2eular(qx, qy, qz, qw):\n",
    "    quaternion = (\n",
    "      qx,\n",
    "      qy,\n",
    "      qz,\n",
    "      qw)\n",
    "    euler = tf.transformations.euler_from_quaternion(quaternion, axes='sxyz')\n",
    "    return euler\n",
    "\n",
    "def go_to_home(wait):\n",
    "    group.clear_pose_targets()\n",
    "    group_variable_values = group.get_current_joint_values()\n",
    "    print \"============ Joint values: \", group_variable_values\n",
    "    group_variable_values[0] = 0 #pi/2\n",
    "    group_variable_values[1] = -pi*81.05/180 #81.05\n",
    "    group_variable_values[2] = -pi*128.91/180 #128.91\n",
    "    group_variable_values[3] = -pi*3/2-(group_variable_values[1]+group_variable_values[2])#-pi/2-(group_variable_values[1]+group_variable_values[2])\n",
    "    group_variable_values[4] = pi*1/2#-pi*1/2\n",
    "    group_variable_values[5] = -pi/2#pi/2\n",
    "    group.set_joint_value_target(group_variable_values)\n",
    "    plan = group.plan()\n",
    "    print \"============ Waiting while RVIZ displays plan2...\"\n",
    "    rospy.sleep(2)\n",
    "    scaled_traj2 = scale_trajectory_speed(plan, 0.2)\n",
    "    group.execute(scaled_traj2, wait)\n",
    "    \n",
    "def move_waypoints(px, py, pz, vel, wait):\n",
    "    waypoints = []\n",
    "    waypoints.append(group.get_current_pose().pose)\n",
    "    wpose = copy.deepcopy(group.get_current_pose().pose)\n",
    "    wpose.position.x = px\n",
    "    wpose.position.y = py\n",
    "    wpose.position.z = pz\n",
    "    waypoints.append(copy.deepcopy(wpose))\n",
    "    (plan, fraction) = group.compute_cartesian_path(\n",
    "                               waypoints,   # waypoints to follow\n",
    "                               0.01,        # eef_step\n",
    "                               0.0)         # jump_threshold\n",
    "    print \"============ Waiting while RVIZ displays plan3...\"\n",
    "    scaled_traj = scale_trajectory_speed(plan, vel)\n",
    "    group.execute(scaled_traj, wait)       \n",
    "\n",
    "def move_joint(theta0, theta1, theta2, theta3, theta4, theta5, vel):\n",
    "    group.clear_pose_targets()\n",
    "    group_variable_values = group.get_current_joint_values()\n",
    "    group_variable_values[0] += theta0\n",
    "    group_variable_values[1] += theta1\n",
    "    group_variable_values[2] += theta2\n",
    "    group_variable_values[3] += theta3\n",
    "    group_variable_values[4] += theta4\n",
    "    group_variable_values[5] += theta5\n",
    "    group.set_joint_value_target(group_variable_values)\n",
    "    plan = group.plan()\n",
    "    print \"============ Waiting while RVIZ displays plan2...\"\n",
    "    scaled_traj2 = scale_trajectory_speed(plan, vel)\n",
    "    group.execute(scaled_traj2)\n",
    "\n",
    "def move_target(x, y, z, ox, oy, oz, ow, vel, wait):\n",
    "    pose_target = geometry_msgs.msg.Pose()\n",
    "    pose_target.orientation.x = ox\n",
    "    pose_target.orientation.y = oy\n",
    "    pose_target.orientation.z = oz\n",
    "    pose_target.orientation.w = ow\n",
    "    pose_target.position.x = x\n",
    "    pose_target.position.y = y\n",
    "    pose_target.position.z = z\n",
    "    group.set_pose_target(pose_target)\n",
    "    plan = group.plan()\n",
    "    scaled_traj = scale_trajectory_speed(plan, vel)\n",
    "    print \"============ Waiting while RVIZ displays plan1...\"\n",
    "    group.execute(scaled_traj, wait)\n",
    "\n",
    "\n",
    "def move_frame(x, y, z, rx, ry, rz, vel, tg_frame, wait):\n",
    "    (base_g_trans,base_g_rot) = listener.lookupTransform('/base_link', tg_frame, rospy.Time(0)) #express frame arg2 in frame arg1\n",
    "    base_g_rot_mat = tf.transformations.quaternion_matrix(base_g_rot)\n",
    "    zaxis = (0, 0, 1)\n",
    "    yaxis = (0, 1, 0)\n",
    "    xaxis = (1, 0, 0)\n",
    "    Rx = tf.transformations.rotation_matrix(rx, xaxis)\n",
    "    Ry = tf.transformations.rotation_matrix(ry, yaxis)\n",
    "    Rz = tf.transformations.rotation_matrix(rz, zaxis)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat, Rx)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat_new, Ry)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat_new, Rz)\n",
    "    #print \"new gri mat\", base_g_rot_mat_new\n",
    "    move_frame_xyz = numpy.array([x, y, z, 1])\n",
    "    base_g_rot_mat[:3,3] = numpy.array(base_g_trans)\n",
    "    base_g_trans_new = numpy.dot(base_g_rot_mat, move_frame_xyz)\n",
    "    base_g_rot_mat_new[:3,3] = numpy.array([base_g_trans_new[0], base_g_trans_new[1], base_g_trans_new[2]])\n",
    "\n",
    "    (g_ee_trans,g_ee_rot) = listener.lookupTransform(tg_frame, '/ee_link', rospy.Time(0)) #express frame arg2 in frame arg1\n",
    "    g_ee_rot_mat = tf.transformations.quaternion_matrix(g_ee_rot)\n",
    "    g_ee_rot_mat[:3,3] = numpy.array(g_ee_trans)\n",
    "    \n",
    "    base_ee_homo_new = numpy.dot(base_g_rot_mat_new, g_ee_rot_mat)\n",
    "    desire_ee_trans = base_ee_homo_new[:3,3]\n",
    "    #base_ee_homo_new[:3,3] = numpy.array([0, 0, 0])\n",
    "    desire_ee_euler = tf.transformations.euler_from_matrix(base_ee_homo_new, axes='sxyz')\n",
    "    desire_ee_q = tf.transformations.quaternion_from_euler(desire_ee_euler[0], desire_ee_euler[1], desire_ee_euler[2], axes='sxyz')\n",
    "    if rx != 0.0 or ry!= 0.0 or rz != 0.0:\n",
    "        move_target(desire_ee_trans[0], desire_ee_trans[1], desire_ee_trans[2], desire_ee_q[0], desire_ee_q[1], desire_ee_q[2], desire_ee_q[3], vel, wait)\n",
    "    else:\n",
    "        move_waypoints(desire_ee_trans[0], desire_ee_trans[1], desire_ee_trans[2], vel, wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate CvBridge\n",
    "bridge = CvBridge()\n",
    "\n",
    "whether_left = True\n",
    "whether_finish = True\n",
    "\n",
    "#def st_callback(data):\n",
    "#    global is_send_img\n",
    "#    #print data.status.data\n",
    "#    is_send_img = data.status.data\n",
    "#    print is_send_img\n",
    "def execution():\n",
    "    global whether_finish\n",
    "    # go down\n",
    "    whether_finish = False\n",
    "    #go down\n",
    "    if whether_finish == False:\n",
    "        print \"before move\"\n",
    "        move_frame(0.1, 0, 0, 0, 0, 0, 0.05, 'ee_link', False)  #0.095\n",
    "        print \"after move\"\n",
    "        \n",
    "def sensor_callback(data):\n",
    "    pressure_raw = data.data\n",
    "    #print \"raw data\", pressure_raw\n",
    "    global whether_finish\n",
    "    #regular expression\n",
    "    pattern = re.compile(r'\\d+')\n",
    "    temp_pres_char_list = re.findall(pattern, pressure_raw)\n",
    "    pres_int_list = []\n",
    "    for i in temp_pres_char_list:\n",
    "        pres_int_list.append(int(i))\n",
    "    if whether_finish == False:\n",
    "        # print whether_tilt\n",
    "        if min(pres_int_list)<300:\n",
    "            #print \"current pressure\", pres_int_list\n",
    "            print \"min xiaoyu 200\"\n",
    "            group.stop()\n",
    "            # whether_tilt = True\n",
    "            print \"200 stop\"\n",
    "            #rospy.sleep(0.5)\n",
    "            #######################################\n",
    "            # grasp\n",
    "            gripper_position(155) # 220 for long # 175 for new blister\n",
    "            #rospy.sleep(1)\n",
    "            #######################################\n",
    "            go_to_home(True)\n",
    "            gripper_position(130) # 150 for long\n",
    "            rospy.sleep(5)\n",
    "            whether_finish = True\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Joint values:  [-0.00010759035219365387, -1.414382282887594, -2.2496212164508265, -1.0482247511493128, 1.5707865953445435, -1.570833985005514]\n",
      "============ Waiting while RVIZ displays plan2...\n",
      "before move\n",
      "============ Waiting while RVIZ displays plan3...\n",
      "after move\n",
      "min xiaoyu 200\n",
      "200 stop\n",
      "============ Joint values:  [5.992112710373476e-05, -1.5401862303363245, -2.349705759678976, -0.8222010771380823, 1.570738673210144, -1.5709059874164026]\n",
      "============ Waiting while RVIZ displays plan2...\n"
     ]
    }
   ],
   "source": [
    "#rospy.init_node('image_listener')\n",
    "\n",
    "#img_count_pub = rospy.Publisher('/img_index', String, queue_size=10)\n",
    "# Set up your subscriber and define its callback\n",
    "rospy.Subscriber(\"/pressure\", String, sensor_callback, queue_size=10)\n",
    "\n",
    "go_to_home(True)\n",
    "global gripper_pub\n",
    "gripper_pub = rospy.Publisher('/robot_gripper_auto_control', String, queue_size=10)\n",
    "gripper_set_vel_pub = rospy.Publisher('CModelRobotOutput', outputMsg.CModel_robot_output, queue_size=10)\n",
    "rospy.sleep(0.5)\n",
    "gripper_pub.publish('a') # a\n",
    "rospy.sleep(0.5)\n",
    "gripper_position(130) #140 for large blister # 150 for 2 parallel jaw\n",
    "#gripper_pub.publish('60') # 150\n",
    "rospy.sleep(4)\n",
    "execution()\n",
    "#gripper_position(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min xiaoyu 200\n",
      "200 stop\n",
      "============ Joint values:  [-0.00010759035219365387, -1.5400546232806605, -2.349490229283468, -0.8225129286395472, 1.570726752281189, -1.570833985005514]\n",
      "============ Waiting while RVIZ displays plan2...\n"
     ]
    }
   ],
   "source": [
    "# Define your image topic\n",
    "#image_topic = \"/usb_cam/image_raw\"\n",
    "\n",
    "#img_count_pub = rospy.Publisher('/img_index', String, queue_size=10)\n",
    "# Set up your subscriber and define its callback\n",
    "#rospy.Subscriber(image_topic, Image, image_callback)\n",
    "#rospy.Subscriber(\"/blister_pose\", blister_pose, pose_callback)\n",
    "#rospy.Subscriber(\"/send_image\", img_status, st_callback)\n",
    "# Spin until ctrl + c\n",
    "#rospy.spin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
