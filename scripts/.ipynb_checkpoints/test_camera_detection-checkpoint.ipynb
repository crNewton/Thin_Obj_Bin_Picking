{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# ROS packages\n",
    "import numpy as np\n",
    "import rospy\n",
    "import geometry_msgs.msg\n",
    "import time\n",
    "import roslib; roslib.load_manifest('ur_driver')\n",
    "import actionlib\n",
    "# ROS Image message\n",
    "from sensor_msgs.msg import Image\n",
    "from std_msgs.msg import String\n",
    "from thin_obj_bin_picking.msg import img_status\n",
    "# ROS Image message -> OpenCV2 image converter\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "#import tf\n",
    "\n",
    "import numpy\n",
    "import sys\n",
    "import copy\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "import tf\n",
    "import math\n",
    "from sensor_msgs.msg import JointState\n",
    "from math import pi, sin, cos, atan2\n",
    "from moveit_msgs.msg import RobotTrajectory\n",
    "from trajectory_msgs.msg import JointTrajectoryPoint\n",
    "from geometry_msgs.msg import PoseStamped, Pose\n",
    "from math import sqrt, pi, acos, sin, cos\n",
    "from robotiq_force_torque_sensor.msg import ft_sensor\n",
    "from robotiq_c_model_control.msg import _CModel_robot_output as outputMsg\n",
    "from thin_obj_bin_picking.msg import blister_pose\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Starting tutorial setup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ros/kinetic/lib/python2.7/dist-packages/moveit_commander/planning_scene_interface.py:49: SyntaxWarning: The publisher should be created with an explicit keyword argument 'queue_size'. Please see http://wiki.ros.org/rospy/Overview/Publishers%20and%20Subscribers for more information.\n",
      "  self._pub_co = rospy.Publisher('/collision_object', CollisionObject)\n",
      "/opt/ros/kinetic/lib/python2.7/dist-packages/moveit_commander/planning_scene_interface.py:50: SyntaxWarning: The publisher should be created with an explicit keyword argument 'queue_size'. Please see http://wiki.ros.org/rospy/Overview/Publishers%20and%20Subscribers for more information.\n",
      "  self._pub_aco = rospy.Publisher('/attached_collision_object', AttachedCollisionObject)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Waiting for RVIZ...\n",
      "============ Starting tutorial \n",
      "============ Reference frame: /world\n",
      "============ Reference frame: ee_link\n",
      "============ Robot Groups:\n",
      "['endeffector', 'manipulator']\n",
      "============ Printing robot state\n",
      "joint_state: \n",
      "  header: \n",
      "    seq: 0\n",
      "    stamp: \n",
      "      secs: 0\n",
      "      nsecs:         0\n",
      "    frame_id: \"/world\"\n",
      "  name: [shoulder_pan_joint, shoulder_lift_joint, elbow_joint, wrist_1_joint, wrist_2_joint,\n",
      "  wrist_3_joint]\n",
      "  position: [-0.0690234343158167, -1.5010650793658655, -2.0655387083636683, -1.1453526655780237, 1.5705589056015015, -1.4948743025409144]\n",
      "  velocity: []\n",
      "  effort: []\n",
      "multi_dof_joint_state: \n",
      "  header: \n",
      "    seq: 0\n",
      "    stamp: \n",
      "      secs: 0\n",
      "      nsecs:         0\n",
      "    frame_id: \"/world\"\n",
      "  joint_names: []\n",
      "  transforms: []\n",
      "  twist: []\n",
      "  wrench: []\n",
      "attached_collision_objects: []\n",
      "is_diff: False\n",
      "============\n"
     ]
    }
   ],
   "source": [
    "listener = tf.TransformListener()\n",
    "\n",
    "## First initialize moveit_commander and rospy.\n",
    "print \"============ Starting tutorial setup\"\n",
    "moveit_commander.roscpp_initialize(sys.argv)\n",
    "rospy.init_node('blister_pick',\n",
    "                  anonymous=True)\n",
    "robot = moveit_commander.RobotCommander()\n",
    "scene = moveit_commander.PlanningSceneInterface()\n",
    "group = moveit_commander.MoveGroupCommander(\"manipulator\")\n",
    "\n",
    "print \"============ Waiting for RVIZ...\"\n",
    "print \"============ Starting tutorial \"\n",
    "\n",
    "print \"============ Reference frame: %s\" % group.get_planning_frame()\n",
    "\n",
    "print \"============ Reference frame: %s\" % group.get_end_effector_link()\n",
    "\n",
    "print \"============ Robot Groups:\"\n",
    "print robot.get_group_names()\n",
    "\n",
    "print \"============ Printing robot state\"\n",
    "print robot.get_current_state()\n",
    "print \"============\"\n",
    "  \n",
    "display_trajectory_publisher = rospy.Publisher(\n",
    "                                    '/move_group/display_planned_path',\n",
    "                                    moveit_msgs.msg.DisplayTrajectory,\n",
    "                                    queue_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_trajectory_speed(traj, scale):\n",
    "       # Create a new trajectory object\n",
    "        new_traj = RobotTrajectory()\n",
    "      \n",
    "       # Initialize the new trajectory to be the same as the planned trajectory\n",
    "        new_traj.joint_trajectory = traj.joint_trajectory\n",
    "      \n",
    "       # Get the number of joints involved\n",
    "        n_joints = len(traj.joint_trajectory.joint_names)\n",
    "      \n",
    "       # Get the number of points on the trajectory\n",
    "        n_points = len(traj.joint_trajectory.points)\n",
    "       \n",
    "       # Store the trajectory points\n",
    "        points = list(traj.joint_trajectory.points)\n",
    "      \n",
    "       # Cycle through all points and scale the time from start, speed and acceleration\n",
    "        for i in range(n_points):\n",
    "            point = JointTrajectoryPoint()\n",
    "            point.time_from_start = traj.joint_trajectory.points[i].time_from_start / scale\n",
    "            point.velocities = list(traj.joint_trajectory.points[i].velocities)\n",
    "            point.accelerations = list(traj.joint_trajectory.points[i].accelerations)\n",
    "            point.positions = traj.joint_trajectory.points[i].positions\n",
    "                        \n",
    "            for j in range(n_joints):\n",
    "                point.velocities[j] = point.velocities[j] * scale\n",
    "                point.accelerations[j] = point.accelerations[j] * scale * scale\n",
    "           \n",
    "            points[i] = point\n",
    "\n",
    "       # Assign the modified points to the new trajectory\n",
    "        new_traj.joint_trajectory.points = points\n",
    "        \n",
    "       # Return the new trajecotry\n",
    "        return new_traj\n",
    "\n",
    "def gripper_position(degree):\n",
    "    command = outputMsg.CModel_robot_output();\n",
    "    command.rACT = 1\n",
    "    command.rGTO = 1\n",
    "    command.rPR = degree\n",
    "    command.rSP  = 0\n",
    "    command.rFR  = 150 ##force need to be adjusted later\n",
    "    gripper_set_vel_pub.publish(command)\n",
    "    \n",
    "    \n",
    "def add_collision_object(xp, yp, zp, rx, ry, rz, rw, x_length, y_length, z_length, name):\n",
    "    ## Add collision object\n",
    "    obj_pose = geometry_msgs.msg.PoseStamped()\n",
    "    obj_pose.header.frame_id = robot.get_planning_frame()\n",
    "    obj_pose.pose.position.x = xp\n",
    "    obj_pose.pose.position.y = yp\n",
    "    obj_pose.pose.position.z = zp\n",
    "    obj_pose.pose.orientation.x = rx\n",
    "    obj_pose.pose.orientation.y = ry\n",
    "    obj_pose.pose.orientation.z = rz\n",
    "    obj_pose.pose.orientation.w = rw\n",
    "    scene.add_box(name, obj_pose, (x_length, y_length, z_length)) # x_axis, y_axis, z_axis\n",
    "    #print \"add collision\", obj_pose\n",
    "\n",
    "def quat2eular(qx, qy, qz, qw):\n",
    "    quaternion = (\n",
    "      qx,\n",
    "      qy,\n",
    "      qz,\n",
    "      qw)\n",
    "    euler = tf.transformations.euler_from_quaternion(quaternion, axes='sxyz')\n",
    "    return euler\n",
    "\n",
    "def go_to_home(wait):\n",
    "    group.clear_pose_targets()\n",
    "    group_variable_values = group.get_current_joint_values()\n",
    "    print \"============ Joint values: \", group_variable_values\n",
    "    group_variable_values[0] = 0 #pi/2\n",
    "    group_variable_values[1] = -pi*68.03/180 #81.05\n",
    "    group_variable_values[2] = -pi*137.81/180 #128.91\n",
    "    group_variable_values[3] = -pi*3/2-(group_variable_values[1]+group_variable_values[2])#-pi/2-(group_variable_values[1]+group_variable_values[2])\n",
    "    group_variable_values[4] = pi*1/2#-pi*1/2\n",
    "    group_variable_values[5] = -pi/2#pi/2\n",
    "    group.set_joint_value_target(group_variable_values)\n",
    "    plan = group.plan()\n",
    "    print \"============ Waiting while RVIZ displays plan2...\"\n",
    "    rospy.sleep(2)\n",
    "    scaled_traj2 = scale_trajectory_speed(plan, 0.2)\n",
    "    group.execute(scaled_traj2, wait)\n",
    "    \n",
    "def move_waypoints(px, py, pz, vel, wait):\n",
    "    waypoints = []\n",
    "    waypoints.append(group.get_current_pose().pose)\n",
    "    wpose = copy.deepcopy(group.get_current_pose().pose)\n",
    "    wpose.position.x = px\n",
    "    wpose.position.y = py\n",
    "    wpose.position.z = pz\n",
    "    waypoints.append(copy.deepcopy(wpose))\n",
    "    (plan, fraction) = group.compute_cartesian_path(\n",
    "                               waypoints,   # waypoints to follow\n",
    "                               0.01,        # eef_step\n",
    "                               0.0)         # jump_threshold\n",
    "    print \"============ Waiting while RVIZ displays plan3...\"\n",
    "    scaled_traj = scale_trajectory_speed(plan, vel)\n",
    "    group.execute(scaled_traj, wait)       \n",
    "\n",
    "def move_joint(theta0, theta1, theta2, theta3, theta4, theta5, vel):\n",
    "    group.clear_pose_targets()\n",
    "    group_variable_values = group.get_current_joint_values()\n",
    "    group_variable_values[0] += theta0\n",
    "    group_variable_values[1] += theta1\n",
    "    group_variable_values[2] += theta2\n",
    "    group_variable_values[3] += theta3\n",
    "    group_variable_values[4] += theta4\n",
    "    group_variable_values[5] += theta5\n",
    "    group.set_joint_value_target(group_variable_values)\n",
    "    plan = group.plan()\n",
    "    print \"============ Waiting while RVIZ displays plan2...\"\n",
    "    scaled_traj2 = scale_trajectory_speed(plan, vel)\n",
    "    group.execute(scaled_traj2)\n",
    "\n",
    "def move_target(x, y, z, ox, oy, oz, ow, vel, wait):\n",
    "    pose_target = geometry_msgs.msg.Pose()\n",
    "    pose_target.orientation.x = ox\n",
    "    pose_target.orientation.y = oy\n",
    "    pose_target.orientation.z = oz\n",
    "    pose_target.orientation.w = ow\n",
    "    pose_target.position.x = x\n",
    "    pose_target.position.y = y\n",
    "    pose_target.position.z = z\n",
    "    group.set_pose_target(pose_target)\n",
    "    plan = group.plan()\n",
    "    scaled_traj = scale_trajectory_speed(plan, vel)\n",
    "    print \"============ Waiting while RVIZ displays plan1...\"\n",
    "    group.execute(scaled_traj, wait)\n",
    "\n",
    "\n",
    "def move_frame(x, y, z, rx, ry, rz, vel, tg_frame, wait):\n",
    "    (base_g_trans,base_g_rot) = listener.lookupTransform('/base_link', tg_frame, rospy.Time(0)) #express frame arg2 in frame arg1\n",
    "    base_g_rot_mat = tf.transformations.quaternion_matrix(base_g_rot)\n",
    "    zaxis = (0, 0, 1)\n",
    "    yaxis = (0, 1, 0)\n",
    "    xaxis = (1, 0, 0)\n",
    "    Rx = tf.transformations.rotation_matrix(rx, xaxis)\n",
    "    Ry = tf.transformations.rotation_matrix(ry, yaxis)\n",
    "    Rz = tf.transformations.rotation_matrix(rz, zaxis)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat, Rx)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat_new, Ry)\n",
    "    base_g_rot_mat_new = numpy.dot(base_g_rot_mat_new, Rz)\n",
    "    #print \"new gri mat\", base_g_rot_mat_new\n",
    "    move_frame_xyz = numpy.array([x, y, z, 1])\n",
    "    base_g_rot_mat[:3,3] = numpy.array(base_g_trans)\n",
    "    base_g_trans_new = numpy.dot(base_g_rot_mat, move_frame_xyz)\n",
    "    base_g_rot_mat_new[:3,3] = numpy.array([base_g_trans_new[0], base_g_trans_new[1], base_g_trans_new[2]])\n",
    "\n",
    "    (g_ee_trans,g_ee_rot) = listener.lookupTransform(tg_frame, '/ee_link', rospy.Time(0)) #express frame arg2 in frame arg1\n",
    "    g_ee_rot_mat = tf.transformations.quaternion_matrix(g_ee_rot)\n",
    "    g_ee_rot_mat[:3,3] = numpy.array(g_ee_trans)\n",
    "    \n",
    "    base_ee_homo_new = numpy.dot(base_g_rot_mat_new, g_ee_rot_mat)\n",
    "    desire_ee_trans = base_ee_homo_new[:3,3]\n",
    "    #base_ee_homo_new[:3,3] = numpy.array([0, 0, 0])\n",
    "    desire_ee_euler = tf.transformations.euler_from_matrix(base_ee_homo_new, axes='sxyz')\n",
    "    desire_ee_q = tf.transformations.quaternion_from_euler(desire_ee_euler[0], desire_ee_euler[1], desire_ee_euler[2], axes='sxyz')\n",
    "    if rx != 0.0 or ry!= 0.0 or rz != 0.0:\n",
    "        move_target(desire_ee_trans[0], desire_ee_trans[1], desire_ee_trans[2], desire_ee_q[0], desire_ee_q[1], desire_ee_q[2], desire_ee_q[3], vel, wait)\n",
    "    else:\n",
    "        move_waypoints(desire_ee_trans[0], desire_ee_trans[1], desire_ee_trans[2], vel, wait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_send_img = 0\n",
    "img_count = 0\n",
    "pose_x = 0\n",
    "pose_y = 0\n",
    "angle = 0\n",
    "# Instantiate CvBridge\n",
    "bridge = CvBridge()\n",
    "\n",
    "whether_left = True\n",
    "whether_finish = True\n",
    "whether_tilt = False\n",
    "left_sensor_bd = 0\n",
    "right_sensor_bd = 0\n",
    "\n",
    "#def st_callback(data):\n",
    "#    global is_send_img\n",
    "#    #print data.status.data\n",
    "#    is_send_img = data.status.data\n",
    "#    print is_send_img\n",
    "def pose_callback(data):\n",
    "    global pose_x, pose_y, angle, whether_left, whether_finish, whether_tilt, left_sensor_bd, right_sensor_bd, is_send_img, pres_int_list_temp\n",
    "    pose_x = data.x\n",
    "    pose_y = data.y\n",
    "    angle = data.angle\n",
    "    left_sensor_bd = 0\n",
    "    right_sensor_bd = 0\n",
    "    whether_tilt = False\n",
    "    \n",
    "    print pose_x, pose_y, angle\n",
    "    (c_ee_trans,c_ee_rot) = listener.lookupTransform('/ee_link', '/camera_link', rospy.Time(0)) #express frame arg2 in frame arg1\n",
    "    print c_ee_rot\n",
    "    c_ee_homo = tf.transformations.quaternion_matrix(c_ee_rot)\n",
    "    print c_ee_homo\n",
    "    c_ee_homo[:3,3] = np.array([c_ee_trans[0], c_ee_trans[1], c_ee_trans[2]])\n",
    "    target_pos = np.dot(c_ee_homo, np.array([pose_x, pose_y, 0, 1]))\n",
    "    print target_pos\n",
    "    #move_frame(0, target_pos[1], target_pos[2], 0, 0, 0, 0.1, 'ee_link', True)\n",
    "    move_frame(0, pose_y-0.16375, -pose_x-0.0045 0, 0, 0, 0.2, 'ee_link', True)\n",
    "    rospy.sleep(0.5)\n",
    "    move_frame(0, 0, 0, pi/2+angle*pi/180, 0, 0, 0.2, 'ee_link', True)\n",
    "    rospy.sleep(0.5)\n",
    "    #move_frame(0, 0.01, 0, 0, 0, 0, 0.1, 'ee_link', True) # shift to one side\n",
    "    #rospy.sleep(0.5)\n",
    "    print \"move move move\"\n",
    "\n",
    "\n",
    "def image_callback(msg):\n",
    "    global img_count\n",
    "    global is_send_img\n",
    "    global pose_x, pose_y, angle\n",
    "    img_count_pub = rospy.Publisher('/img_index', String, queue_size=1)\n",
    "    if is_send_img == 1:\n",
    "        cv2_img = bridge.imgmsg_to_cv2(msg, \"bgr8\")\n",
    "        cv2.imwrite('../image/'+str(img_count)+'.jpeg', cv2_img)\n",
    "        img_count_pub.publish(str(img_count))\n",
    "        rospy.sleep(1)\n",
    "        print str(img_count)\n",
    "        img_count =img_count + 1\n",
    "        is_send_img = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Joint values:  [-0.06901151338686162, -1.5010412375079554, -2.065526787434713, -1.1453283468829554, 1.5705230236053467, -1.4949219862567347]\n",
      "============ Waiting while RVIZ displays plan2...\n"
     ]
    }
   ],
   "source": [
    "#rospy.init_node('image_listener')\n",
    "\n",
    "image_topic = '/camera/color/image_raw' #\"/usb_cam/image_raw\"\n",
    "\n",
    "img_count_pub = rospy.Publisher('/img_index', String, queue_size=10)\n",
    "# Set up your subscriber and define its callback\n",
    "rospy.Subscriber(image_topic, Image, image_callback)\n",
    "rospy.Subscriber(\"/blister_pose\", blister_pose, pose_callback)\n",
    "go_to_home(False)\n",
    "global gripper_pub\n",
    "gripper_pub = rospy.Publisher('/robot_gripper_auto_control', String, queue_size=10)\n",
    "gripper_set_vel_pub = rospy.Publisher('CModelRobotOutput', outputMsg.CModel_robot_output, queue_size=10)\n",
    "rospy.sleep(0.5)\n",
    "gripper_pub.publish('a') # a\n",
    "rospy.sleep(0.5)\n",
    "gripper_position(130)\n",
    "#gripper_pub.publish('60') # 150\n",
    "rospy.sleep(6)\n",
    "#gripper_position(0)\n",
    "#rospy.sleep(0.5)\n",
    "is_send_img = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0325398496241 -0.0196285714286 -176.34777722\n",
      "[0.0, 0.7071067811865475, 0.0, 0.7071067811865476]\n",
      "[[ 0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.]\n",
      " [-1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.]]\n",
      "[ 0.09       -0.18337857 -0.03453985  1.        ]\n",
      "============ Waiting while RVIZ displays plan3...\n",
      "============ Waiting while RVIZ displays plan1...\n",
      "move move move\n"
     ]
    }
   ],
   "source": [
    "# Define your image topic\n",
    "#image_topic = \"/usb_cam/image_raw\"\n",
    "\n",
    "#img_count_pub = rospy.Publisher('/img_index', String, queue_size=10)\n",
    "# Set up your subscriber and define its callback\n",
    "#rospy.Subscriber(image_topic, Image, image_callback)\n",
    "#rospy.Subscriber(\"/blister_pose\", blister_pose, pose_callback)\n",
    "#rospy.Subscriber(\"/send_image\", img_status, st_callback)\n",
    "# Spin until ctrl + c\n",
    "#rospy.spin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
